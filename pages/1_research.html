---
bg: "research_bg.png"
layout: page
title: "Research"
crawlertitle: "MMA"
permalink: /research/
summary: "Research projects"
active: true
---

<div class="scibox">
    <img class="science-image" src="{{ site.images }}/AA_summary_for_website_v2.png" alt="test image">  
    <h4><a href="https://www.biorxiv.org/content/10.1101/2023.01.31.526307v1.full.pdf">Potentiated cholinergic and corticofugal inputs support 
        reorganized sensory processing in the basolateral amygdala during auditory threat acquisition and retrieval</a> 
    </h4>
    <h5><u>Asokan, M.M.</u>, Watanabe, Y., Kimchi, E.Y., and Polley, D.B., bioRxiv 2023</h5>
    </a>
    <p>
    The neural basis of discriminative threat memory is typically indexed through measurements from one brain area, 
        which fails to capture how the functional coupling across a distributed network of brain areas supports threat memory acquisition and recall. 
        To understand whether inputs to BLA are also reorganized during discriminative threat learning, we performed multi-regional measurements of 
        acetylcholine (ACh) release, single unit spiking, and functional coupling in the BLA and higher-order auditory cortex (HO-AC) of mice. 
        Our findings showcase a remarkable plasticity in the afferent inputs to the amygdala – both descending projections from neocortex and cholinergic 
        inputs from the basal forebrain – that parallel the reorganization observed within the amygdala. Further, we identify 
        the enhanced functional coupling between the neocortex and the amygdala as a signature of threat memory and an example 
        for the distributed brain-wide changes that are widely believed to support adaptive behavioral changes but are less often directly tested. I
        presented this work as posters at the Optogenetics GRC 2022 and APAN 2021.
    </p>
</div>

<div class="scibox">
    <img class="science-image" src="{{ site.images }}/asokan_2020_currbio.png" alt="test image">  
    <h4><a href="https://www.sciencedirect.com/science/article/pii/S096098222100141X?dgcid=author">Inverted central auditory hierarchies for encoding
local intervals and global temporal patterns
    </a></h4>
    <h5><u>Asokan, M.M.,</u> Williamson, R.S., Hancock, K.E. and Polley, D.B., Current Biology 2021</h5>
    </a>
    <p>
        With simultaneous unit recordings from the mouse auditory
        midbrain, thalamus, and cortex, we look at transformation of neural coding along the 
        auditory neuro-axis and we find inverted hierarchies in neural coding of sensory features
        with different temporal scales. We observed that the decay constants for sound-evoked spiking
        increased from the midbrain to cortex, and that the cortical timescale
        was itself shaped by slower changes in stimulus context,
        such that rhythmic, predictable sequences featured more
        orderly first spike latencies and more strongly dampened spiking
        decay. These findings show that low-level auditory neurons with fast timescales encode isolated
        sound features but not the longer gestalt, while the extended timescales in higher-level areas can facilitate
        sensitivity to slower contextual changes in the sensory environment. I presented this work in a number of conferences 
        including <a href="{{ site.images }}/shbt_midwinterforum_2020_final_pdf_mma.png">NCCD 2019</a>, 
        <a href="{{ site.images }}/cosyne_2020_v4_withtext_final.png">Cosyne 2020</a>, and <a href="https://www.crowdcast.io/e/apan-2020/4">APAN 2020</a>
        where I was awarded for one of the 
        <a href = "https://www.med.upenn.edu/apan/previous-keynote-speakers-young-investigator-spotlight-presentation-awards.html">best oral presentations</a>. 
    </p>
</div>

<div class="scibox">
    <img class="science-image" src="{{ site.images }}/asokan_2018_natcomm.png" alt="test image">  
    <h4><a href="https://www.nature.com/articles/s41467-018-04852-y">Sensory overamplification in layer 5 auditory corticofugal projection neurons
        following cochlear nerve synaptic damage
    </a></h4>
    <h5><u>Asokan, M.M.,</u> Williamson, R.S., Hancock, K.E. and Polley, D.B., Nature Communications 2018</h5>
    </a>
    <p>
        Layer 5 (L5) cortical projection neurons innervate far-ranging brain areas including inferior colliculus (IC), 
        thalamus, lateral amygdala and striatum to coordinate integrative sensory processing 
        and adaptive behaviors. We track daily changes in sound processing 
        using chronic widefield calcium imaging of L5 axon terminals on the dorsal cap of the IC in awake, adult mice. 
        After noise-induced damage of cochlear afferent synapses, the corticocollicular response gain rebounded above baseline levels 
        by the following day and remained elevated for several weeks despite a persistent reduction in auditory nerve input.
        Sustained potentiation of these projection neurons that innervate multiple limbic and subcortical auditory centers may 
        underlie the increased anxiety, stress and other forms of mood dysregulation experienced by subjects who acquire perceptual disorders
        such as tinnitus and hyperacusis after hearing loss. I presented this work as a poster 
        at <a href="{{ site.images }}/sfn_2017_mma_56_42_v3_final.png">SfN 2017</a>, and also received travel awards to present the work as podium talks at 
        <a href="{{ site.images }}/ICACProgram2017.pdf">ICAC 2017</a> and ARO 2018. 
    </p>
</div>


<div class="scibox">
    <img class="science-image" src="{{ site.images }}/clayton_2020_frontiers.png" alt="test image">  
    <h4><a href="https://www.frontiersin.org/articles/10.3389/fnins.2021.666627/full">Behavioral approaches to reveal top-down influences on active listening
    </a></h4>
    <h5>Clayton, K.K, <u>Asokan, M.M.,</u> Watanabe, Y., Hancock, K.E. and Polley, D.B., Frontiers in Neuroscience 2021</h5>
    </a>
    <p>
        Knowing when to listen can enhance the detection of faint sounds or the
        discrimination of target sounds from distractors. We found that periodicity aided the detectability of a
        liminal repeating target in a complex background noise by increasing the probability of
        late detection events, after the regularity of the target sound had been established. 
        The prolonged time course of repetition-based stream segregation suggests a
        mechanism by which repetitive inputs are integrated over time and used to predict the
        incoming acoustic signal. Our work provides behavioral proof-of-principle for future
        studies to uncover the neural substrates of this prolonged temporal integration process
        in a genetically-tractable model organism.
    </p>
</div>
















